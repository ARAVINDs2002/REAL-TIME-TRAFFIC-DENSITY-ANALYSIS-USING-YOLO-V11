{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69b017e9-984a-4029-a0f7-21f44e9f380a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 car, 202.2ms\n",
      "Speed: 7.6ms preprocess, 202.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 207.8ms\n",
      "Speed: 3.1ms preprocess, 207.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 196.9ms\n",
      "Speed: 6.1ms preprocess, 196.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 192.6ms\n",
      "Speed: 6.1ms preprocess, 192.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 198.9ms\n",
      "Speed: 2.0ms preprocess, 198.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 204.7ms\n",
      "Speed: 3.0ms preprocess, 204.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 199.9ms\n",
      "Speed: 3.0ms preprocess, 199.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 193.2ms\n",
      "Speed: 1.6ms preprocess, 193.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 201.0ms\n",
      "Speed: 3.0ms preprocess, 201.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 192.6ms\n",
      "Speed: 3.0ms preprocess, 192.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AOI coordinates saved: [(121, 563)]\n",
      "\n",
      "0: 384x640 2 cars, 201.1ms\n",
      "Speed: 3.0ms preprocess, 201.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 199.8ms\n",
      "Speed: 3.0ms preprocess, 199.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 201.6ms\n",
      "Speed: 3.0ms preprocess, 201.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 198.4ms\n",
      "Speed: 3.0ms preprocess, 198.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 195.9ms\n",
      "Speed: 3.0ms preprocess, 195.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 194.2ms\n",
      "Speed: 5.0ms preprocess, 194.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AOI coordinates saved: [(121, 563), (517, 322)]\n",
      "\n",
      "0: 384x640 2 cars, 203.5ms\n",
      "Speed: 4.0ms preprocess, 203.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 205.2ms\n",
      "Speed: 3.0ms preprocess, 205.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 194.9ms\n",
      "Speed: 5.0ms preprocess, 194.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 199.1ms\n",
      "Speed: 3.0ms preprocess, 199.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 189.5ms\n",
      "Speed: 3.0ms preprocess, 189.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AOI coordinates saved: [(121, 563), (517, 322), (630, 330)]\n",
      "\n",
      "0: 384x640 2 cars, 208.1ms\n",
      "Speed: 3.0ms preprocess, 208.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 203.0ms\n",
      "Speed: 7.0ms preprocess, 203.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 218.2ms\n",
      "Speed: 6.0ms preprocess, 218.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 206.4ms\n",
      "Speed: 3.0ms preprocess, 206.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 198.0ms\n",
      "Speed: 6.0ms preprocess, 198.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AOI coordinates saved: [(121, 563), (517, 322), (630, 330), (552, 622)]\n",
      "\n",
      "0: 384x640 2 cars, 196.0ms\n",
      "Speed: 2.0ms preprocess, 196.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 195.1ms\n",
      "Speed: 4.0ms preprocess, 195.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 216.2ms\n",
      "Speed: 3.0ms preprocess, 216.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 202.0ms\n",
      "Speed: 3.0ms preprocess, 202.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 176.0ms\n",
      "Speed: 3.0ms preprocess, 176.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 211.0ms\n",
      "Speed: 3.0ms preprocess, 211.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 185.6ms\n",
      "Speed: 3.0ms preprocess, 185.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 197.8ms\n",
      "Speed: 2.0ms preprocess, 197.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 197.2ms\n",
      "Speed: 5.0ms preprocess, 197.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 195.1ms\n",
      "Speed: 6.0ms preprocess, 195.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 190.8ms\n",
      "Speed: 4.0ms preprocess, 190.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 180.3ms\n",
      "Speed: 3.2ms preprocess, 180.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 175.0ms\n",
      "Speed: 4.0ms preprocess, 175.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 181.0ms\n",
      "Speed: 4.0ms preprocess, 181.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 187.0ms\n",
      "Speed: 3.0ms preprocess, 187.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 180.0ms\n",
      "Speed: 2.0ms preprocess, 180.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 188.1ms\n",
      "Speed: 3.0ms preprocess, 188.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 183.8ms\n",
      "Speed: 3.0ms preprocess, 183.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 184.0ms\n",
      "Speed: 2.0ms preprocess, 184.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 187.0ms\n",
      "Speed: 4.0ms preprocess, 187.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 191.7ms\n",
      "Speed: 3.0ms preprocess, 191.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 191.8ms\n",
      "Speed: 3.0ms preprocess, 191.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 181.4ms\n",
      "Speed: 5.0ms preprocess, 181.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 184.9ms\n",
      "Speed: 5.0ms preprocess, 184.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 183.9ms\n",
      "Speed: 4.0ms preprocess, 183.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 186.0ms\n",
      "Speed: 3.0ms preprocess, 186.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 185.7ms\n",
      "Speed: 4.0ms preprocess, 185.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 194.4ms\n",
      "Speed: 3.0ms preprocess, 194.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 196.2ms\n",
      "Speed: 3.0ms preprocess, 196.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 187.2ms\n",
      "Speed: 2.0ms preprocess, 187.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 190.2ms\n",
      "Speed: 2.0ms preprocess, 190.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed 57 frames in 13.17 seconds (4.33 FPS)\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import json\n",
    "import time\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load a pre-trained YOLOv8 model\n",
    "best_model = YOLO('yolo11n.pt')\n",
    "\n",
    "# Define traffic intensity thresholds\n",
    "MILD_THRESHOLD = 4   # Number of vehicles for low traffic\n",
    "STRONG_THRESHOLD = 6  # Number of vehicles for medium traffic\n",
    "\n",
    "# Open the video\n",
    "cap = cv2.VideoCapture('l1.mp4')\n",
    "\n",
    "# Get frame dimensions\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "# Create the processed frames directory if it doesn't exist\n",
    "output_folder = 'processed_frames'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Create the ground truth folder\n",
    "ground_truth_folder = 'ground_truth'\n",
    "os.makedirs(ground_truth_folder, exist_ok=True)\n",
    "\n",
    "# Flags for mouse events\n",
    "drawing = False\n",
    "polygon_points = []\n",
    "\n",
    "# Function to save AOI coordinates to a JSON file\n",
    "def save_aoi_coordinates(points):\n",
    "    with open('aoi_coordinates.json', 'w') as f:\n",
    "        json.dump(points, f)\n",
    "    print(\"AOI coordinates saved:\", points)\n",
    "\n",
    "# Mouse callback function to draw polygon\n",
    "def draw_polygon(event, x, y, flags, param):\n",
    "    global drawing, polygon_points\n",
    "    \n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        polygon_points.append((x, y))\n",
    "        save_aoi_coordinates(polygon_points)\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE and drawing:\n",
    "        frame_copy = frame.copy()\n",
    "        if len(polygon_points) > 0:\n",
    "            cv2.polylines(frame_copy, [np.array(polygon_points)], isClosed=False, color=(0, 255, 0), thickness=2)\n",
    "        cv2.circle(frame_copy, (x, y), 5, (0, 0, 255), -1)\n",
    "        cv2.imshow('Real-time Traffic Analysis', frame_copy)\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "\n",
    "# Create a named window and set mouse callback\n",
    "cv2.namedWindow('Real-time Traffic Analysis')\n",
    "cv2.setMouseCallback('Real-time Traffic Analysis', draw_polygon)\n",
    "\n",
    "# Font and display settings\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_scale = 0.5\n",
    "font_color = (255, 255, 255)\n",
    "\n",
    "# Start time for FPS calculation\n",
    "start_time = time.time()\n",
    "frame_count = 0\n",
    "\n",
    "# Initialize lists for metrics\n",
    "all_ground_truths = []\n",
    "all_predictions = []\n",
    "\n",
    "# Data for Excel logging\n",
    "excel_data = []\n",
    "\n",
    "# Read video frames\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    detection_frame = frame.copy()\n",
    "    results = best_model.predict(detection_frame, imgsz=640, conf=0.4)\n",
    "    processed_frame = results[0].plot(line_width=1)\n",
    "\n",
    "    if len(polygon_points) > 0:\n",
    "        cv2.polylines(processed_frame, [np.array(polygon_points)], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "    bounding_boxes = results[0].boxes\n",
    "    vehicles_in_aoi = 0\n",
    "    ground_truth = []\n",
    "    predictions = []\n",
    "\n",
    "    for box, class_id in zip(bounding_boxes.xyxy, bounding_boxes.cls):\n",
    "        class_name = best_model.names[int(class_id)]\n",
    "        box_center = ((box[0] + box[2]) / 2, (box[1] + box[3]) / 2)\n",
    "        box_center = (int(box_center[0]), int(box_center[1]))\n",
    "        \n",
    "        ground_truth.append({'class': class_name, 'coordinates': [float(box[0]), float(box[1]), float(box[2]), float(box[3])]})\n",
    "        predictions.append(1)\n",
    "\n",
    "        if len(polygon_points) > 0 and cv2.pointPolygonTest(np.array(polygon_points, dtype=np.int32), box_center, False) >= 0:\n",
    "            vehicles_in_aoi += 1\n",
    "\n",
    "    ground_truth_path = os.path.join(ground_truth_folder, f'frame_{frame_count}.json')\n",
    "    with open(ground_truth_path, 'w') as f:\n",
    "        json.dump(ground_truth, f)\n",
    "\n",
    "    if vehicles_in_aoi == 0:\n",
    "        traffic_intensity = \"No Traffic\"\n",
    "        font_color = (255, 0, 0)\n",
    "    elif 1 <= vehicles_in_aoi <= MILD_THRESHOLD:\n",
    "        traffic_intensity = \"Low Traffic\"\n",
    "        font_color = (0, 165, 255)\n",
    "    elif MILD_THRESHOLD < vehicles_in_aoi <= STRONG_THRESHOLD:\n",
    "        traffic_intensity = \"Medium Traffic\"\n",
    "        font_color = (0, 255, 255)\n",
    "    else:\n",
    "        traffic_intensity = \"High Traffic\"\n",
    "        font_color = (0, 0, 255)\n",
    "\n",
    "    cv2.putText(processed_frame, f'Vehicles in AOI: {vehicles_in_aoi}', (10, 50), font, font_scale, font_color, 2, cv2.LINE_AA)\n",
    "    cv2.putText(processed_frame, f'Traffic Intensity: {traffic_intensity}', (10, 100), font, font_scale, font_color, 2, cv2.LINE_AA)\n",
    "\n",
    "    output_frame_path = os.path.join(output_folder, f'processed_frame_{frame_count}.jpg')\n",
    "    cv2.imwrite(output_frame_path, processed_frame)\n",
    "\n",
    "    all_ground_truths.extend(ground_truth)\n",
    "    all_predictions.extend(predictions)\n",
    "\n",
    "    excel_data.append({'Frame': frame_count, 'Vehicles in AOI': vehicles_in_aoi, 'Traffic Intensity': traffic_intensity})\n",
    "\n",
    "    frame_count += 1\n",
    "    cv2.imshow('Real-time Traffic Analysis', processed_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "fps = frame_count / elapsed_time\n",
    "print(f\"Processed {frame_count} frames in {elapsed_time:.2f} seconds ({fps:.2f} FPS)\")\n",
    "\n",
    "# Metrics evaluation\n",
    "ground_truth_labels = [1 if gt['class'] != 'unknown' else 0 for gt in all_ground_truths]\n",
    "precision = precision_score(ground_truth_labels, all_predictions)\n",
    "recall = recall_score(ground_truth_labels, all_predictions)\n",
    "f1 = f1_score(ground_truth_labels, all_predictions)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")\n",
    "\n",
    "# Save data to Excel\n",
    "df = pd.DataFrame(excel_data)\n",
    "df.to_excel('traffic_analysis_log.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6704ec3-850c-442b-b323-d52287f8617a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 car, 289.8ms\n",
      "Speed: 4.0ms preprocess, 289.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 227.0ms\n",
      "Speed: 6.0ms preprocess, 227.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 226.9ms\n",
      "Speed: 4.0ms preprocess, 226.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 232.0ms\n",
      "Speed: 3.0ms preprocess, 232.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 224.9ms\n",
      "Speed: 3.0ms preprocess, 224.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 221.9ms\n",
      "Speed: 4.5ms preprocess, 221.9ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 219.8ms\n",
      "Speed: 3.0ms preprocess, 219.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AOI coordinates saved: [(158, 536)]\n",
      "\n",
      "0: 384x640 2 cars, 226.7ms\n",
      "Speed: 3.0ms preprocess, 226.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 219.9ms\n",
      "Speed: 2.0ms preprocess, 219.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 220.5ms\n",
      "Speed: 3.0ms preprocess, 220.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 206.8ms\n",
      "Speed: 2.0ms preprocess, 206.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AOI coordinates saved: [(158, 536), (570, 296)]\n",
      "\n",
      "0: 384x640 2 cars, 221.8ms\n",
      "Speed: 5.2ms preprocess, 221.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 219.0ms\n",
      "Speed: 3.0ms preprocess, 219.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 215.0ms\n",
      "Speed: 2.0ms preprocess, 215.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 truck, 205.0ms\n",
      "Speed: 5.0ms preprocess, 205.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AOI coordinates saved: [(158, 536), (570, 296), (641, 307)]\n",
      "\n",
      "0: 384x640 2 cars, 213.0ms\n",
      "Speed: 3.0ms preprocess, 213.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 205.0ms\n",
      "Speed: 2.0ms preprocess, 205.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 210.0ms\n",
      "Speed: 2.0ms preprocess, 210.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 215.0ms\n",
      "Speed: 3.0ms preprocess, 215.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 208.0ms\n",
      "Speed: 3.0ms preprocess, 208.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AOI coordinates saved: [(158, 536), (570, 296), (641, 307), (556, 600)]\n",
      "\n",
      "0: 384x640 2 cars, 208.0ms\n",
      "Speed: 3.0ms preprocess, 208.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 214.0ms\n",
      "Speed: 4.0ms preprocess, 214.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 209.0ms\n",
      "Speed: 5.0ms preprocess, 209.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 207.0ms\n",
      "Speed: 3.0ms preprocess, 207.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 212.0ms\n",
      "Speed: 3.0ms preprocess, 212.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 205.0ms\n",
      "Speed: 4.0ms preprocess, 205.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 211.0ms\n",
      "Speed: 3.0ms preprocess, 211.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 208.5ms\n",
      "Speed: 5.0ms preprocess, 208.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 204.7ms\n",
      "Speed: 3.0ms preprocess, 204.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 205.1ms\n",
      "Speed: 3.0ms preprocess, 205.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 209.7ms\n",
      "Speed: 5.0ms preprocess, 209.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 206.0ms\n",
      "Speed: 2.0ms preprocess, 206.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 201.8ms\n",
      "Speed: 6.0ms preprocess, 201.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 198.4ms\n",
      "Speed: 7.0ms preprocess, 198.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 211.4ms\n",
      "Speed: 4.1ms preprocess, 211.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 215.2ms\n",
      "Speed: 4.0ms preprocess, 215.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 192.7ms\n",
      "Speed: 2.0ms preprocess, 192.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 196.0ms\n",
      "Speed: 3.0ms preprocess, 196.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 197.0ms\n",
      "Speed: 4.0ms preprocess, 197.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 198.0ms\n",
      "Speed: 3.0ms preprocess, 198.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 208.0ms\n",
      "Speed: 3.0ms preprocess, 208.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 205.0ms\n",
      "Speed: 3.0ms preprocess, 205.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 198.0ms\n",
      "Speed: 2.0ms preprocess, 198.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 195.0ms\n",
      "Speed: 3.0ms preprocess, 195.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 201.2ms\n",
      "Speed: 4.0ms preprocess, 201.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 196.0ms\n",
      "Speed: 2.0ms preprocess, 196.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 193.0ms\n",
      "Speed: 4.0ms preprocess, 193.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 198.0ms\n",
      "Speed: 5.0ms preprocess, 198.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 200.0ms\n",
      "Speed: 2.0ms preprocess, 200.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 197.0ms\n",
      "Speed: 2.0ms preprocess, 197.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 195.0ms\n",
      "Speed: 4.0ms preprocess, 195.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 192.0ms\n",
      "Speed: 5.0ms preprocess, 192.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 206.0ms\n",
      "Speed: 2.0ms preprocess, 206.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 196.9ms\n",
      "Speed: 3.0ms preprocess, 196.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 193.3ms\n",
      "Speed: 3.0ms preprocess, 193.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 196.7ms\n",
      "Speed: 3.9ms preprocess, 196.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 203.1ms\n",
      "Speed: 3.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 197.8ms\n",
      "Speed: 4.0ms preprocess, 197.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 199.8ms\n",
      "Speed: 3.0ms preprocess, 199.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 200.2ms\n",
      "Speed: 2.0ms preprocess, 200.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 205.9ms\n",
      "Speed: 3.8ms preprocess, 205.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 193.0ms\n",
      "Speed: 4.0ms preprocess, 193.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 195.4ms\n",
      "Speed: 3.9ms preprocess, 195.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 197.0ms\n",
      "Speed: 2.0ms preprocess, 197.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 203.0ms\n",
      "Speed: 2.0ms preprocess, 203.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 200.0ms\n",
      "Speed: 2.0ms preprocess, 200.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 196.0ms\n",
      "Speed: 4.0ms preprocess, 196.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 200.0ms\n",
      "Speed: 3.0ms preprocess, 200.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 201.0ms\n",
      "Speed: 8.0ms preprocess, 201.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 199.0ms\n",
      "Speed: 3.0ms preprocess, 199.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 205.0ms\n",
      "Speed: 5.0ms preprocess, 205.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed 71 frames in 17.22 seconds (4.12 FPS)\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import json\n",
    "import time\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load a pre-trained YOLOv8 model\n",
    "best_model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Define traffic intensity thresholds\n",
    "MILD_THRESHOLD = 4   # Number of vehicles for low traffic\n",
    "STRONG_THRESHOLD = 6  # Number of vehicles for medium traffic\n",
    "\n",
    "# Open the video\n",
    "cap = cv2.VideoCapture('l1.mp4')\n",
    "\n",
    "# Get frame dimensions\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "# Create the processed frames directory if it doesn't exist\n",
    "output_folder = 'processed_frames'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Create the ground truth folder\n",
    "ground_truth_folder = 'ground_truth'\n",
    "os.makedirs(ground_truth_folder, exist_ok=True)\n",
    "\n",
    "# Flags for mouse events\n",
    "drawing = False\n",
    "polygon_points = []\n",
    "\n",
    "# Function to save AOI coordinates to a JSON file\n",
    "def save_aoi_coordinates(points):\n",
    "    with open('aoi_coordinates.json', 'w') as f:\n",
    "        json.dump(points, f)\n",
    "    print(\"AOI coordinates saved:\", points)\n",
    "\n",
    "# Mouse callback function to draw polygon\n",
    "def draw_polygon(event, x, y, flags, param):\n",
    "    global drawing, polygon_points\n",
    "    \n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        polygon_points.append((x, y))\n",
    "        save_aoi_coordinates(polygon_points)\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE and drawing:\n",
    "        frame_copy = frame.copy()\n",
    "        if len(polygon_points) > 0:\n",
    "            cv2.polylines(frame_copy, [np.array(polygon_points)], isClosed=False, color=(0, 255, 0), thickness=2)\n",
    "        cv2.circle(frame_copy, (x, y), 5, (0, 0, 255), -1)\n",
    "        cv2.imshow('Real-time Traffic Analysis', frame_copy)\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "\n",
    "# Create a named window and set mouse callback\n",
    "cv2.namedWindow('Real-time Traffic Analysis')\n",
    "cv2.setMouseCallback('Real-time Traffic Analysis', draw_polygon)\n",
    "\n",
    "# Font and display settings\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_scale = 0.5\n",
    "font_color = (255, 255, 255)\n",
    "\n",
    "# Start time for FPS calculation\n",
    "start_time = time.time()\n",
    "frame_count = 0\n",
    "\n",
    "# Initialize lists for metrics\n",
    "all_ground_truths = []\n",
    "all_predictions = []\n",
    "\n",
    "# Data for Excel logging\n",
    "excel_data = []\n",
    "\n",
    "# Read video frames\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    detection_frame = frame.copy()\n",
    "    results = best_model.predict(detection_frame, imgsz=640, conf=0.4)\n",
    "    processed_frame = results[0].plot(line_width=1)\n",
    "\n",
    "    if len(polygon_points) > 0:\n",
    "        cv2.polylines(processed_frame, [np.array(polygon_points)], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "    bounding_boxes = results[0].boxes\n",
    "    vehicles_in_aoi = 0\n",
    "    ground_truth = []\n",
    "    predictions = []\n",
    "\n",
    "    for box, class_id in zip(bounding_boxes.xyxy, bounding_boxes.cls):\n",
    "        class_name = best_model.names[int(class_id)]\n",
    "        box_center = ((box[0] + box[2]) / 2, (box[1] + box[3]) / 2)\n",
    "        box_center = (int(box_center[0]), int(box_center[1]))\n",
    "        \n",
    "        ground_truth.append({'class': class_name, 'coordinates': [float(box[0]), float(box[1]), float(box[2]), float(box[3])]})\n",
    "        predictions.append(1)\n",
    "\n",
    "        if len(polygon_points) > 0 and cv2.pointPolygonTest(np.array(polygon_points, dtype=np.int32), box_center, False) >= 0:\n",
    "            vehicles_in_aoi += 1\n",
    "\n",
    "    ground_truth_path = os.path.join(ground_truth_folder, f'frame_{frame_count}.json')\n",
    "    with open(ground_truth_path, 'w') as f:\n",
    "        json.dump(ground_truth, f)\n",
    "\n",
    "    if vehicles_in_aoi == 0:\n",
    "        traffic_intensity = \"No Traffic\"\n",
    "        font_color = (255, 0, 0)\n",
    "    elif 1 <= vehicles_in_aoi <= MILD_THRESHOLD:\n",
    "        traffic_intensity = \"Low Traffic\"\n",
    "        font_color = (0, 165, 255)\n",
    "    elif MILD_THRESHOLD < vehicles_in_aoi <= STRONG_THRESHOLD:\n",
    "        traffic_intensity = \"Medium Traffic\"\n",
    "        font_color = (0, 255, 255)\n",
    "    else:\n",
    "        traffic_intensity = \"High Traffic\"\n",
    "        font_color = (0, 0, 255)\n",
    "\n",
    "    cv2.putText(processed_frame, f'Vehicles in AOI: {vehicles_in_aoi}', (10, 50), font, font_scale, font_color, 2, cv2.LINE_AA)\n",
    "    cv2.putText(processed_frame, f'Traffic Intensity: {traffic_intensity}', (10, 100), font, font_scale, font_color, 2, cv2.LINE_AA)\n",
    "\n",
    "    output_frame_path = os.path.join(output_folder, f'processed_frame_{frame_count}.jpg')\n",
    "    cv2.imwrite(output_frame_path, processed_frame)\n",
    "\n",
    "    all_ground_truths.extend(ground_truth)\n",
    "    all_predictions.extend(predictions)\n",
    "\n",
    "    excel_data.append({'Frame': frame_count, 'Vehicles in AOI': vehicles_in_aoi, 'Traffic Intensity': traffic_intensity})\n",
    "\n",
    "    frame_count += 1\n",
    "    cv2.imshow('Real-time Traffic Analysis', processed_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "fps = frame_count / elapsed_time\n",
    "print(f\"Processed {frame_count} frames in {elapsed_time:.2f} seconds ({fps:.2f} FPS)\")\n",
    "\n",
    "# Metrics evaluation\n",
    "ground_truth_labels = [1 if gt['class'] != 'unknown' else 0 for gt in all_ground_truths]\n",
    "precision = precision_score(ground_truth_labels, all_predictions)\n",
    "recall = recall_score(ground_truth_labels, all_predictions)\n",
    "f1 = f1_score(ground_truth_labels, all_predictions)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")\n",
    "\n",
    "# Save data to Excel\n",
    "df = pd.DataFrame(excel_data)\n",
    "df.to_excel('traffic_analysis_log.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "730b9d45-b661-4a98-a3f2-818e4a501c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP  Replace 'model=yolov5n.pt' with new 'model=yolov5nu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "\n",
      "0: 384x640 1 car, 205.0ms\n",
      "Speed: 6.2ms preprocess, 205.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 219.8ms\n",
      "Speed: 4.0ms preprocess, 219.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 212.5ms\n",
      "Speed: 5.7ms preprocess, 212.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 209.3ms\n",
      "Speed: 3.3ms preprocess, 209.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 202.4ms\n",
      "Speed: 3.0ms preprocess, 202.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 208.9ms\n",
      "Speed: 5.0ms preprocess, 208.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 209.9ms\n",
      "Speed: 6.0ms preprocess, 209.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 196.9ms\n",
      "Speed: 2.0ms preprocess, 196.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 199.2ms\n",
      "Speed: 4.0ms preprocess, 199.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 196.6ms\n",
      "Speed: 3.0ms preprocess, 196.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AOI coordinates saved: [(168, 524)]\n",
      "\n",
      "0: 384x640 2 cars, 202.6ms\n",
      "Speed: 3.0ms preprocess, 202.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 203.4ms\n",
      "Speed: 3.0ms preprocess, 203.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 205.2ms\n",
      "Speed: 3.0ms preprocess, 205.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 204.0ms\n",
      "Speed: 5.0ms preprocess, 204.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 200.0ms\n",
      "Speed: 3.0ms preprocess, 200.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 199.0ms\n",
      "Speed: 6.0ms preprocess, 199.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 194.8ms\n",
      "Speed: 6.0ms preprocess, 194.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AOI coordinates saved: [(168, 524), (552, 301)]\n",
      "\n",
      "0: 384x640 2 cars, 201.7ms\n",
      "Speed: 4.0ms preprocess, 201.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 203.2ms\n",
      "Speed: 5.0ms preprocess, 203.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 194.3ms\n",
      "Speed: 2.0ms preprocess, 194.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 197.0ms\n",
      "Speed: 4.0ms preprocess, 197.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AOI coordinates saved: [(168, 524), (552, 301), (634, 317)]\n",
      "\n",
      "0: 384x640 1 car, 207.5ms\n",
      "Speed: 6.0ms preprocess, 207.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 204.7ms\n",
      "Speed: 3.0ms preprocess, 204.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 211.9ms\n",
      "Speed: 3.0ms preprocess, 211.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 198.4ms\n",
      "Speed: 3.0ms preprocess, 198.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 193.1ms\n",
      "Speed: 4.0ms preprocess, 193.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "AOI coordinates saved: [(168, 524), (552, 301), (634, 317), (557, 602)]\n",
      "\n",
      "0: 384x640 1 car, 202.0ms\n",
      "Speed: 3.0ms preprocess, 202.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 203.7ms\n",
      "Speed: 4.0ms preprocess, 203.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 197.8ms\n",
      "Speed: 3.0ms preprocess, 197.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 205.7ms\n",
      "Speed: 3.0ms preprocess, 205.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 203.5ms\n",
      "Speed: 3.0ms preprocess, 203.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 185.3ms\n",
      "Speed: 2.0ms preprocess, 185.3ms inference, 13.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 190.2ms\n",
      "Speed: 3.0ms preprocess, 190.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 194.4ms\n",
      "Speed: 4.4ms preprocess, 194.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 178.4ms\n",
      "Speed: 3.6ms preprocess, 178.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 192.2ms\n",
      "Speed: 3.0ms preprocess, 192.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 189.5ms\n",
      "Speed: 6.2ms preprocess, 189.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 194.9ms\n",
      "Speed: 3.0ms preprocess, 194.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 185.8ms\n",
      "Speed: 3.7ms preprocess, 185.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 190.4ms\n",
      "Speed: 3.0ms preprocess, 190.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 193.3ms\n",
      "Speed: 3.0ms preprocess, 193.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 185.3ms\n",
      "Speed: 6.0ms preprocess, 185.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 190.2ms\n",
      "Speed: 3.0ms preprocess, 190.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 190.5ms\n",
      "Speed: 3.0ms preprocess, 190.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 186.5ms\n",
      "Speed: 3.0ms preprocess, 186.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 196.9ms\n",
      "Speed: 3.0ms preprocess, 196.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 189.3ms\n",
      "Speed: 3.0ms preprocess, 189.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 189.7ms\n",
      "Speed: 2.0ms preprocess, 189.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 171.4ms\n",
      "Speed: 4.0ms preprocess, 171.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 191.7ms\n",
      "Speed: 7.2ms preprocess, 191.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 189.2ms\n",
      "Speed: 3.0ms preprocess, 189.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 196.8ms\n",
      "Speed: 3.0ms preprocess, 196.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 190.9ms\n",
      "Speed: 2.5ms preprocess, 190.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 188.8ms\n",
      "Speed: 3.0ms preprocess, 188.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 185.0ms\n",
      "Speed: 7.6ms preprocess, 185.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 192.0ms\n",
      "Speed: 2.0ms preprocess, 192.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 175.4ms\n",
      "Speed: 5.6ms preprocess, 175.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 183.7ms\n",
      "Speed: 5.0ms preprocess, 183.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed 58 frames in 13.58 seconds (4.27 FPS)\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import json\n",
    "import time\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load a pre-trained YOLOv8 model\n",
    "best_model = YOLO('yolov5n.pt')\n",
    "\n",
    "# Define traffic intensity thresholds\n",
    "MILD_THRESHOLD = 4   # Number of vehicles for low traffic\n",
    "STRONG_THRESHOLD = 6  # Number of vehicles for medium traffic\n",
    "\n",
    "# Open the video\n",
    "cap = cv2.VideoCapture('l1.mp4')\n",
    "\n",
    "# Get frame dimensions\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "# Create the processed frames directory if it doesn't exist\n",
    "output_folder = 'processed_frames'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Create the ground truth folder\n",
    "ground_truth_folder = 'ground_truth'\n",
    "os.makedirs(ground_truth_folder, exist_ok=True)\n",
    "\n",
    "# Flags for mouse events\n",
    "drawing = False\n",
    "polygon_points = []\n",
    "\n",
    "# Function to save AOI coordinates to a JSON file\n",
    "def save_aoi_coordinates(points):\n",
    "    with open('aoi_coordinates.json', 'w') as f:\n",
    "        json.dump(points, f)\n",
    "    print(\"AOI coordinates saved:\", points)\n",
    "\n",
    "# Mouse callback function to draw polygon\n",
    "def draw_polygon(event, x, y, flags, param):\n",
    "    global drawing, polygon_points\n",
    "    \n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        polygon_points.append((x, y))\n",
    "        save_aoi_coordinates(polygon_points)\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE and drawing:\n",
    "        frame_copy = frame.copy()\n",
    "        if len(polygon_points) > 0:\n",
    "            cv2.polylines(frame_copy, [np.array(polygon_points)], isClosed=False, color=(0, 255, 0), thickness=2)\n",
    "        cv2.circle(frame_copy, (x, y), 5, (0, 0, 255), -1)\n",
    "        cv2.imshow('Real-time Traffic Analysis', frame_copy)\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "\n",
    "# Create a named window and set mouse callback\n",
    "cv2.namedWindow('Real-time Traffic Analysis')\n",
    "cv2.setMouseCallback('Real-time Traffic Analysis', draw_polygon)\n",
    "\n",
    "# Font and display settings\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_scale = 0.5\n",
    "font_color = (255, 255, 255)\n",
    "\n",
    "# Start time for FPS calculation\n",
    "start_time = time.time()\n",
    "frame_count = 0\n",
    "\n",
    "# Initialize lists for metrics\n",
    "all_ground_truths = []\n",
    "all_predictions = []\n",
    "\n",
    "# Data for Excel logging\n",
    "excel_data = []\n",
    "\n",
    "# Read video frames\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    detection_frame = frame.copy()\n",
    "    results = best_model.predict(detection_frame, imgsz=640, conf=0.4)\n",
    "    processed_frame = results[0].plot(line_width=1)\n",
    "\n",
    "    if len(polygon_points) > 0:\n",
    "        cv2.polylines(processed_frame, [np.array(polygon_points)], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "    bounding_boxes = results[0].boxes\n",
    "    vehicles_in_aoi = 0\n",
    "    ground_truth = []\n",
    "    predictions = []\n",
    "\n",
    "    for box, class_id in zip(bounding_boxes.xyxy, bounding_boxes.cls):\n",
    "        class_name = best_model.names[int(class_id)]\n",
    "        box_center = ((box[0] + box[2]) / 2, (box[1] + box[3]) / 2)\n",
    "        box_center = (int(box_center[0]), int(box_center[1]))\n",
    "        \n",
    "        ground_truth.append({'class': class_name, 'coordinates': [float(box[0]), float(box[1]), float(box[2]), float(box[3])]})\n",
    "        predictions.append(1)\n",
    "\n",
    "        if len(polygon_points) > 0 and cv2.pointPolygonTest(np.array(polygon_points, dtype=np.int32), box_center, False) >= 0:\n",
    "            vehicles_in_aoi += 1\n",
    "\n",
    "    ground_truth_path = os.path.join(ground_truth_folder, f'frame_{frame_count}.json')\n",
    "    with open(ground_truth_path, 'w') as f:\n",
    "        json.dump(ground_truth, f)\n",
    "\n",
    "    if vehicles_in_aoi == 0:\n",
    "        traffic_intensity = \"No Traffic\"\n",
    "        font_color = (255, 0, 0)\n",
    "    elif 1 <= vehicles_in_aoi <= MILD_THRESHOLD:\n",
    "        traffic_intensity = \"Low Traffic\"\n",
    "        font_color = (0, 165, 255)\n",
    "    elif MILD_THRESHOLD < vehicles_in_aoi <= STRONG_THRESHOLD:\n",
    "        traffic_intensity = \"Medium Traffic\"\n",
    "        font_color = (0, 255, 255)\n",
    "    else:\n",
    "        traffic_intensity = \"High Traffic\"\n",
    "        font_color = (0, 0, 255)\n",
    "\n",
    "    cv2.putText(processed_frame, f'Vehicles in AOI: {vehicles_in_aoi}', (10, 50), font, font_scale, font_color, 2, cv2.LINE_AA)\n",
    "    cv2.putText(processed_frame, f'Traffic Intensity: {traffic_intensity}', (10, 100), font, font_scale, font_color, 2, cv2.LINE_AA)\n",
    "\n",
    "    output_frame_path = os.path.join(output_folder, f'processed_frame_{frame_count}.jpg')\n",
    "    cv2.imwrite(output_frame_path, processed_frame)\n",
    "\n",
    "    all_ground_truths.extend(ground_truth)\n",
    "    all_predictions.extend(predictions)\n",
    "\n",
    "    excel_data.append({'Frame': frame_count, 'Vehicles in AOI': vehicles_in_aoi, 'Traffic Intensity': traffic_intensity})\n",
    "\n",
    "    frame_count += 1\n",
    "    cv2.imshow('Real-time Traffic Analysis', processed_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "fps = frame_count / elapsed_time\n",
    "print(f\"Processed {frame_count} frames in {elapsed_time:.2f} seconds ({fps:.2f} FPS)\")\n",
    "\n",
    "# Metrics evaluation\n",
    "ground_truth_labels = [1 if gt['class'] != 'unknown' else 0 for gt in all_ground_truths]\n",
    "precision = precision_score(ground_truth_labels, all_predictions)\n",
    "recall = recall_score(ground_truth_labels, all_predictions)\n",
    "f1 = f1_score(ground_truth_labels, all_predictions)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")\n",
    "\n",
    "# Save data to Excel\n",
    "df = pd.DataFrame(excel_data)\n",
    "df.to_excel('traffic_analysis_log.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f581c5-e25d-4182-8b6f-f95216fe8213",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
